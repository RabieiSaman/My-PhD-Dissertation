# importing the necessary packages used to develop the model. 

import pandas as pd
import h5py
from sklearn.preprocessing import StandardScaler
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Attention, Add)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tqdm import tqdm
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.regularizers import l2
import keras_tuner as kt
import matplotlib.pyplot as plt
from keras_tuner import Hyperband
import json
from keras_tuner import HyperParameters
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

------------------------------------------------------------------------------------------------------------------------------
# In this section the code read the csv file contains the information of the satellite observations, remote sensing, and soil survey data. Then separate it into the training, validation, and the testing phase (2017-2022), (2022), and (2023) respectively.
 
# Load the dataset from the provided file
file_path = r'D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Best_Models\SNOTEL_Version_NotFilled\AllStations_(2017-2023)_Final_SMAPL3_COM_MODIS_StaticData.csv'
data = pd.read_csv(file_path)
total_length = len(data)
print("Total length of the dataset:", total_length)
data = data[data['Network'].isin(['SCAN', 'USCRN', 'SNOTEL'])]

# Define predictors and target
predictors = [
    'DEM', 'LandCover', 
    'claytotal_5_cm_p', 'dbovendry_5_cm_p', 'sandtotal_5_cm_p', 
    'silttotal_5_cm_p', 'soc_5_cm_p', 'COM_albedo_dca', 
    'COM_roughness_coefficient_dca', 'COM_soil_moisture_dca', 
    'COM_surface_temperature', 'COM_tb_h_corrected', 'COM_tb_v_corrected', 
    'COM_vegetation_opacity_dca', 'COM_vegetation_water_content',
    'ref_b01', 'ref_b02', 'RTM_ref_b07'
]
target = 'Soil Moisture Percent -2in (pct) Mean of Hourly Values'

# Step 1: Sort the data by the "Date" column in ascending order
data_sorted = data.sort_values(by=["Station ID", "Date"])

# Step 2a: Filter rows where predictors or target have invalid values (-9999 or empty strings)
data_sorted = data_sorted[
    (data_sorted[predictors + [target]] != -9999).all(axis=1) &  # Remove invalid values (-9999)
    (data_sorted[predictors + [target]] != -9900).all(axis=1) &  # Remove invalid values (-9900)
    (data_sorted[target].notna()) &  # Remove rows where target is NaN
    (data_sorted[target].astype(str).str.strip() != '') &  # Remove rows where target is an empty string
    (data_sorted[target].between(1, 100))  # Ensure target is between 0 and 100
]

data_sorted = data_sorted.dropna(subset=predictors + [target])
print(max(data_sorted[target]))
data_sorted[target] = data_sorted[target] / 100
#Creating Train, Validation, and Test phases
data_sorted['Date'] = pd.to_datetime(data_sorted['Date'], format='%Y%m%d')

copy_data = data_sorted.copy()
output_file_path = r'D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Best_Models\SNOTEL_Version_NotFilled\CNN-LSTM_timestep(5)_WithRegularization_SNOTEL_original.csv'
#copy_data.to_csv(output_file_path, index=False)
print('Original Dataset Was Created!')
print(len(copy_data))
all_columns = data.columns

# Step 2: Normalize the predictors using StandardScaler
scaler = StandardScaler()
data_sorted[predictors] = scaler.fit_transform(data_sorted[predictors])


# Define the function to create samples for CNN-LSTM
def create_cnn_lstm_samples(data, predictors, target, time_steps):
    X, y = [], []
    for i in tqdm(range(len(data) - time_steps + 1)):
        X.append(data[predictors].iloc[i:i+time_steps].values)
        y.append(data[target].iloc[i + time_steps - 1])  # Target at the last time step
    return np.array(X), np.array(y)


# Define the date ranges for train, validation, and test sets
train_start = pd.to_datetime("20170101", format="%Y%m%d")
train_end = pd.to_datetime("20220101", format="%Y%m%d")
val_start = pd.to_datetime("20220101", format="%Y%m%d")
val_end = pd.to_datetime("20230101", format="%Y%m%d")
test_start = pd.to_datetime("20230101", format="%Y%m%d")
test_end = pd.to_datetime("20240101", format="%Y%m%d")

# Split data into train, val, and test based on date ranges
train_data = data_sorted[(data_sorted['Date'] >= train_start) & (data_sorted['Date'] < train_end)]
val_data = data_sorted[(data_sorted['Date'] >= val_start) & (data_sorted['Date'] < val_end)]
test_data = data_sorted[(data_sorted['Date'] >= test_start) & (data_sorted['Date'] <= test_end)]
time_steps = 5


------------------------------------------------------------------------------------------------------------------------------
# This section create the 5-day sequential dataset for the training, validation, and test phase and save them as .h5 dataset
# Create samples for each dataset
time_steps = time_steps
print('For Training Dataset')
X_train, y_train = create_cnn_lstm_samples(train_data, predictors, target, time_steps)
print('For Validation Dataset')
X_val, y_val = create_cnn_lstm_samples(val_data, predictors, target, time_steps)
print('For Testing Dataset')
X_test, y_test = create_cnn_lstm_samples(test_data, predictors, target, time_steps)
print('For Original Test Dataset')
X_test_o, y_test_o = create_cnn_lstm_samples(test_data, all_columns, target, time_steps)

# Filepath to save the datasets
output_filepath = r"C:\project\cnn_lstm_dataset_lookback(5)_Alldataset_SNOTEL_NotFilled.h5"

# Create and save datasets to an HDF5 file
with h5py.File(output_filepath, "w") as f:
    # Save training data
    f.create_dataset("X_train", data=X_train)
    f.create_dataset("y_train", data=y_train)
    
    # Save validation data
    f.create_dataset("X_val", data=X_val)
    f.create_dataset("y_val", data=y_val)
    
    # Save testing data
    f.create_dataset("X_test", data=X_test)
    f.create_dataset("y_test", data=y_test)

print(f"Datasets saved to {output_filepath}")

------------------------------------------------------------------------------------------------------------------------------
# This the model structure to find the best hyperparameters based on the Keras-Tunner optimization

def build_model(hp):
    # Input layer
    inputs = Input(shape=(time_steps, len(predictors)))

    # CNN Block with tunable filters, kernel size, and dropout
    x = Conv1D(
        filters=hp.Int('filters_cnn', min_value=16, max_value=256, step=16),
        kernel_size=hp.Int('kernel_size', min_value=1, max_value=time_steps, step=1),
        activation=hp.Choice('activation_cnn', values=['relu', 'tanh', 'sigmoid']),
        padding='same'
    )(inputs)
    x = MaxPooling1D(pool_size=2)(x)
    x = Dropout(hp.Float('dropout_cnn', min_value=0.1, max_value=0.5, step=0.1))(x)

    # LSTM Block with tunable units and dropout, reduced to 2 layers
    lstm_out = LSTM(
        hp.Int('units_lstm1', min_value=16, max_value=512, step=16),
        return_sequences=True,
        activation=hp.Choice('activation_lstm', values=['relu', 'tanh', 'sigmoid']),
        recurrent_dropout=hp.Float('recurrent_dropout_lstm1', min_value=0.0, max_value=0.5, step=0.1),
        kernel_regularizer=l2(hp.Float('l2_lstm1', min_value=1e-5, max_value=1e-2, sampling='log'))
    )(x)
    lstm_out = LSTM(
        hp.Int('units_lstm2', min_value=16, max_value=512, step=16),
        return_sequences=False,
        activation=hp.Choice('activation_lstm', values=['relu', 'tanh', 'sigmoid']),
        recurrent_dropout=hp.Float('recurrent_dropout_lstm2', min_value=0.0, max_value=0.5, step=0.1),
        kernel_regularizer=l2(hp.Float('l2_lstm2', min_value=1e-5, max_value=1e-2, sampling='log'))
    )(lstm_out)

    # Fully connected layers with tunable dropout and L2 regularization
    fc = Dense(
        hp.Int('units_dense', min_value=32, max_value=512, step=16),
        activation='relu',
        kernel_regularizer=l2(hp.Float('l2_dense', min_value=1e-5, max_value=1e-2, sampling='log'))
    )(lstm_out)
    fc = Dropout(hp.Float('dropout_dense', min_value=0.1, max_value=0.5, step=0.1))(fc)

    # Output layer
    outputs = Dense(1, activation='sigmoid')(fc)

    # Define the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with tunable learning rate
    model.compile(
        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),
        loss='mean_squared_error',
        metrics=['mae']
    )

    return model

# Set up the tuner

tuner = Hyperband(
    build_model,
    objective='val_loss',
    max_epochs=50,
    factor=3,
    directory='my_dir',
    project_name='cnn_lstm_tuning_with_regularization'
)

# Early stopping callback
stop_early = EarlyStopping(monitor='val_loss', patience=30)

# Define the adaptive learning rate callback
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss', factor=0.5, patience=50, min_lr=1e-6, verbose=1
)

# Search for the best hyperparameters
tuner.search(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=16,
    callbacks=[stop_early]
)

# Retrieve the best model
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"Best filters for CNN: {best_hps.get('filters_cnn')}")
print(f"Best kernel size for CNN: {best_hps.get('kernel_size')}")
print(f"Best activation for CNN: {best_hps.get('activation_cnn')}")
print(f"Best dropout for CNN: {best_hps.get('dropout_cnn')}")
print(f"Best LSTM units (1st layer): {best_hps.get('units_lstm1')}")
print(f"Best LSTM units (2nd layer): {best_hps.get('units_lstm2')}")
print(f"Best activation for LSTM: {best_hps.get('activation_lstm')}")
print(f"Best recurrent dropout (1st layer): {best_hps.get('recurrent_dropout_lstm1')}")
print(f"Best recurrent dropout (2nd layer): {best_hps.get('recurrent_dropout_lstm2')}")
print(f"Best L2 regularization (1st LSTM): {best_hps.get('l2_lstm1')}")
print(f"Best L2 regularization (2nd LSTM): {best_hps.get('l2_lstm2')}")
print(f"Best dense units: {best_hps.get('units_dense')}")
print(f"Best dropout for dense: {best_hps.get('dropout_dense')}")
print(f"Best L2 regularization (dense): {best_hps.get('l2_dense')}")
print(f"Best learning rate: {best_hps.get('learning_rate')}")

------------------------------------------------------------------------------------------------------------------------------
# This section is for the model developing based on the optimized hyperparameters obtained from the previous section and also plot the corresponding graphs

# Build the best model with the best hyperparameters
best_model = tuner.hypermodel.build(best_hps)

# Define the ModelCheckpoint callback
checkpoint = ModelCheckpoint(
    r'D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Best_Models\SNOTEL_Version_NotFilled\CNN-LSTM_timestep(5)_WithRegularization_SNOTEL.h5',  # Filepath to save the model
    monitor='val_loss',  # Metric to monitor
    save_best_only=True,  # Save only the best model
    mode='min',  # Minimize validation loss
    verbose=1
)

# Train the best model
history = best_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=300,
    batch_size=16,
    callbacks=[stop_early, checkpoint]
)

# Plot training and validation loss
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='--')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid()
plt.show()

# Plot training and validation MAE
plt.figure(figsize=(12, 6))
plt.plot(history.history['mae'], label='Training MAE')
plt.plot(history.history['val_mae'], label='Validation MAE', linestyle='--')
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Training and Validation MAE')
plt.legend()
plt.grid()
plt.show()

------------------------------------------------------------------------------------------------------------------------------
#This section is for loading the best developed model weights for applying on the testing phase

# Load the saved model
model_path = r'D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Best_Models\SNOTEL_Without SMAP SM_NotFilled_version\Model_CNN-LSTM_timestep(5)_WithRegularization_Bayesian_withoutSMAPSM_SNOTEL.h5'
best_model = load_model(model_path)

y_pred_scaled = best_model.predict(X_test)
y_pred_scaled = y_pred_scaled.flatten()

print("Combined X shape:", X_test.shape)
print("Combined Y shape:", y_test.shape)
print("Combined X_test_o:", X_test_o.shape)
print("predicted Y shape:", y_pred_scaled.shape)

------------------------------------------------------------------------------------------------------------------------------
# This section is for providing the Error metrics values for the testing phase (2023)

def kge(simulated, observed):

    sim_mean = np.mean(simulated)
    obs_mean = np.mean(observed)
    sim_std = np.std(simulated)
    obs_std = np.std(observed)
    r = np.corrcoef(simulated, observed)[0, 1]  # Correlation coefficient

    # Compute KGE
    kge_value = 1 - np.sqrt((r - 1)**2 + ((sim_std / obs_std) - 1)**2 + ((sim_mean / obs_mean) - 1)**2)
    return kge_value


# Error metrics for the testing phase
rmse_test = ((sum((a - b) ** 2 for a, b in zip(y_test, y_pred_scaled)) / len(y_test))**0.5)*0.01
test_r2 = r2_score(y_test, y_pred_scaled)
test_kge = kge(y_pred_scaled, y_test)


print("\nTesting Phase Metrics:")
print(f"RMSE: {rmse_test:.3f}, RÂ²: {test_r2:.3f}, KGE: {test_kge:.3f}")

------------------------------------------------------------------------------------------------------------------------------
# This section is creating the high resolution (100 m) SM maps for any region of interest (e.g., walnut gulch or little Washita)


from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dropout, LSTM, Dense
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2

# Build the model with manually set hyperparameters
def build_model_with_manual_hps():
    # Input layer
    inputs = Input(shape=(time_steps, len(predictors)))

    # CNN Block
    x = Conv1D(
        filters=384,
        kernel_size=4,
        activation='sigmoid',
        padding='same'
    )(inputs)
    x = MaxPooling1D(pool_size=2)(x)
    #x = Dropout(0.2)(x)

    # LSTM Block
    lstm_out = LSTM(
        416,
        return_sequences=True,
        activation='tanh',
        recurrent_dropout=0,
        kernel_regularizer=l2(1.3121e-05)
    )(x)
    lstm_out = BatchNormalization()(lstm_out)  # Add BatchNormalization

    lstm_out = LSTM(
        416,
        return_sequences=True,
        activation='tanh',
        recurrent_dropout=0,
        kernel_regularizer=l2(1.3121e-05)
    )(lstm_out)
    lstm_out = BatchNormalization()(lstm_out)  # Add BatchNormalization

    lstm_out = LSTM(
        384,
        return_sequences=False,
        activation='relu',
        recurrent_dropout=0.1,
        kernel_regularizer=l2(0.00068496)
    )(lstm_out)
    lstm_out = BatchNormalization()(lstm_out)  # Add BatchNormalization

    # Fully connected layers
    fc = Dense(
        416,
        activation='linear',
        kernel_regularizer=l2(0.0023488)
    )(lstm_out)
    fc = Dropout(0.4)(fc)

    # Output layer
    outputs = Dense(1, activation='linear')(fc)

    # Define the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model
    model.compile(
        optimizer=Adam(learning_rate=0.00085945),
        loss='mean_squared_error',
        metrics=['mae']
    )

    return model

# Instantiate and summarize the model
best_model = build_model_with_manual_hps()
best_model.summary()

stop_early = EarlyStopping(monitor='val_loss', patience=30)
# Define the ModelCheckpoint callback
checkpoint = ModelCheckpoint(
    r'D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Best_Models\SNOTEL_Without SMAP SM_NotFilled_version\Result_Subsurface (20 cm)\Model_Subsurface(8in)_CNN-LSTM_timestep(5)_Bayesian.h5',  # Filepath to save the model
    monitor='val_loss',  # Metric to monitor
    save_best_only=True,  # Save only the best model
    mode='min',  # Minimize validation loss
    verbose=1
)


# Load the saved model
model_path = r'D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Best_Models\SNOTEL_Without SMAP SM_NotFilled_version\Result_Subsurface (20 cm)\Model_Subsurface(8in)_CNN-LSTM_timestep(5)_Bayesian.h5'
best_model = load_model(model_path)

h5_file_path = r"D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Dataset\Little Washita Creek WBDHU10\Modified SMAP Dataset\Subsurface (20cm)_Dataset.h5"
with h5py.File(h5_file_path, 'r') as h5_file:
    h5_data = h5_file['data'][:]  # Replace 'combined_data' with the correct dataset key
    print(f"HDF5 data shape: {h5_data.shape}")

for abc in range(361):
    print(abc, ' is started ...')
    # Step 1: Initialize the output array
    rows, cols, days, channels = h5_data.shape
    output_array = np.zeros((rows * cols, 5, channels))  # Shape: (2211478, 5, 18)
    valid_indices = []  # To store indices of valid samples
    
    # Step 2: Flatten spatial dimensions and handle NaN values
    pixel_index = 0
    for i in tqdm(range(rows)):
        for j in range(cols):
            # Extract 5 sequential days for this pixel across all channels
            sample = h5_data[i, j, abc:abc+5, :]
            if not np.isnan(sample).any():  # Check if the sample contains NaN
                output_array[pixel_index] = sample  # Add valid sample
                valid_indices.append(pixel_index)  # Track valid indices
            pixel_index += 1
    
    # Convert valid_indices to a NumPy array for indexing
    valid_indices = np.array(valid_indices)
    
    # Filter `output_array` to keep only valid samples
    output_array_filtered = output_array[valid_indices]
    print(f"Filtered output array shape: {output_array_filtered.shape}")
    print('instead of ', rows*cols)
    
    output_array_transform = np.full(output_array_filtered.shape, np.nan)
    for i in range(output_array_filtered.shape[1]):  # Loop over the timesteps
        output_array_transform[:, i, :] = scaler_predictors.transform(output_array_filtered[:, i, :]) 
    print(output_array_transform.shape)
    
    y_pred_scaled = best_model.predict(output_array_transform)
    y_pred_scaled1 = scaler_target.inverse_transform(y_pred_scaled).flatten()
    y_pred_full = np.full(rows * cols, np.nan)
    y_pred_full[valid_indices] = y_pred_scaled1[:]
    
    soil_moisture_map = np.full((rows, cols), np.nan)
    # Fill the original array using a nested loop
    pixel_index = 0
    for i in tqdm(range(rows)):
        for j in range(cols):
            soil_moisture_map[i, j] = y_pred_full[pixel_index]
            pixel_index += 1       
            
    print(soil_moisture_map.shape)
    
    source_tiff = r"D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Dataset\Little Washita Creek WBDHU10\Modified SMAP Dataset\SOLUS Data\claytotal_15_cm_p.tif"
    tiff_directory = r"D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Dataset\Little Washita Creek WBDHU10\Modified SMAP Dataset\SPL3SMP_E.006_Soil_Moisture_Retrieval_Data_albedo"
    output_directory = r"D:\PhD_Files\Chapter2_Physics Informed Deep Learning\Best_Models\SNOTEL_Without SMAP SM_NotFilled_version\New_Result_Surface (5cm)\Little Washita Creek WBDHU10\New_Produced_Data\Subsurface (20cm)_Little Washita"
    
    # Extract dates from filenames
    dates = []
    for filename in os.listdir(tiff_directory):
        if filename.endswith(".tif"):
            # Extract date using filename pattern
            parts = filename.split('_')
            dates.append(parts[-1][:-4])  # Extract the date part (e.g., 2023026)
                    
    output_tiff = os.path.join(output_directory, f"Subsurface (20 cm)_Soil_Moisture_100m_Little Washita_{dates[abc+5]}.tif")
    with rasterio.open(source_tiff) as src:
        meta = src.meta.copy()  # Copy the metadata
    meta.update(dtype=rasterio.float32, count=1) 
    with rasterio.open(output_tiff, 'w', **meta) as dst:
        dst.write(soil_moisture_map.astype(rasterio.float32), 1)
    print(f"TIFF file saved as: {output_tiff}")                
    
